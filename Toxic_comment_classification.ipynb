{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic_comment_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/katamit/Data-Science/blob/master/Toxic_comment_classification.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "dw0fhwKBv_-O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# toxic comment classictionaion\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0c6yGjXCwDTi",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "d7b61b9d-d586-405f-ae65-79c96c098dab"
      },
      "cell_type": "code",
      "source": [
        "#upload the kaggle credentials\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-df3b4737-2609-4745-aeb6-e6b70f761f63\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-df3b4737-2609-4745-aeb6-e6b70f761f63\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"katamit\",\"key\":\"0160ce365ba46762f645bb754e33182f\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "d8iEkiNgMBgb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#SETTING GLOBAL VARIABLES\n",
        "EMBEDDINGDIM = 300\n",
        "MAXVOCABSIZE = 175303 \n",
        "MAXSEQLENGTH = 200 \n",
        "batchsize = 256 \n",
        "epochs = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SIW5NRTmwKgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27fcbe11-8620-4082-aeef-7e7050b99226"
      },
      "cell_type": "code",
      "source": [
        "# is it there\n",
        "ls -lha kaggle.json"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 63 Sep 10 04:32 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bt6U_6uDwZKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0db9a1a2-3dc4-4d51-c30d-2beff54dbeba"
      },
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "edit\t     sample_data\t\t\t\t\t wget-log\n",
            "kaggle.json  uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download  wget-log.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wQN1kI6swbLJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#File configuration\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kNfXqIjRwnlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "3f4a4be9-19bc-4731-f267-a4af3abbfc4b"
      },
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 59.3MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 42% 10.0M/23.8M [00:00<00:00, 49.1MB/s]\n",
            "100% 23.8M/23.8M [00:00<00:00, 93.2MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 93% 25.0M/26.7M [00:00<00:00, 42.2MB/s]\n",
            "100% 26.7M/26.7M [00:00<00:00, 101MB/s] \n",
            "Downloading test_labels.csv.zip to /content\n",
            "  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "100% 1.46M/1.46M [00:00<00:00, 236MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zgcSMng1wwAC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "be701fd7-f05d-4f22-b9f2-93b6aaa1abb1"
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/78/832b9a9ec6b3baf8ec566e1f0a695f2fd08d2c94a6797257a106304bfc3c/kaggle-1.4.7.1.tar.gz (52kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.8.24)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.25.0)\n",
            "Collecting python-slugify (from kaggle)\n",
            "  Downloading https://files.pythonhosted.org/packages/00/ad/c778a6df614b6217c30fe80045b365bfa08b5dd3cb02e8b37a6d25126781/python-slugify-1.2.6.tar.gz\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Collecting Unidecode>=0.04.16 (from python-slugify->kaggle)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/ef/67085e30e8bbcdd76e2f0a4ad8151c13a2c5bce77c85f8cad6e1f16fb141/Unidecode-1.0.22-py2.py3-none-any.whl (235kB)\n",
            "\u001b[K    100% |████████████████████████████████| 235kB 6.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify\n",
            "  Running setup.py bdist_wheel for kaggle ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/44/2c/df/22a6eeb780c36c28190faef6252b739fdc47145fd87a6642d4\n",
            "  Running setup.py bdist_wheel for python-slugify ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e3/65/da/2045deea3098ed7471eca0e2460cfbd3fdfe8c1d6fa6fcac92\n",
            "Successfully built kaggle python-slugify\n",
            "Installing collected packages: Unidecode, python-slugify, kaggle\n",
            "Successfully installed Unidecode-1.0.22 kaggle-1.4.7.1 python-slugify-1.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e5xTjei6xBjN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.Data\n",
        "!mv train.csv.zip test.csv.zip test_labels.csv.zip sample_submission.csv.zip ~/.Data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "royiGJilyABH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5ad50982-0e24-486e-8b03-be010206d745"
      },
      "cell_type": "code",
      "source": [
        "!ls ~/.Data"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_submission.csv.zip  test_labels.csv.zip\t     train.csv\n",
            "test.csv\t\t   traincleandata.csv\t     train.csv.zip\n",
            "test.csv.zip\t\t   trainCleanDatatokens.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_3xezE2fy5cE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6f646d87-b1b4-4075-b492-702b86779641"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!unzip ~/.Data/test.csv.zip"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /root/.Data/test.csv.zip\n",
            "  inflating: test.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kt13SptnzE_F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv test.csv ~/.Data/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2AQS_XqfzaVz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#READING AND SETTING UP THE TRAIN.CSV FILE\n",
        "traincomments = pd.read_csv(\"~/.Data/train.csv\", sep=',', header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ylxQ4JApzty8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "fbcd218f-bda6-4323-b9fc-9288d177eaaf"
      },
      "cell_type": "code",
      "source": [
        "traincomments.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0             0        0       0       0              0  \n",
              "1             0        0       0       0              0  \n",
              "2             0        0       0       0              0  \n",
              "3             0        0       0       0              0  \n",
              "4             0        0       0       0              0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "PBOj7raxz8sV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee099587-f022-4ff9-f093-422002de2393"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Num Train:\", traincomments.shape[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num Train: 159571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c3UJ-kZ4z831",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8ecceae-525c-4422-8b0d-2037e67ab7c9"
      },
      "cell_type": "code",
      "source": [
        "label_names = list(traincomments.columns)[2:]\n",
        "print(list(label_names))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SUvluEUaz87E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ytrain = traincomments[label_names].values\n",
        "# print(ytrain.head)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t4IDTbfYz8-R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ytrain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kJIRe_AOz9BR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "167a1f90-8776-4f40-902c-7a0c5115dcf7"
      },
      "cell_type": "code",
      "source": [
        "#READING AND SETTING UP THE TEST.CSV FILE\n",
        "testcomments = pd.read_csv(\"~/.Data/test.csv\", sep=',', header=0)\n",
        "# testcomments.columns=['id', 'comment_text']\n",
        "print(\"num test: \", testcomments.shape[0])\n",
        "testcomments.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num test:  153164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>:If you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>I don't anonymously edit articles at all.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text\n",
              "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
              "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
              "4  00017695ad8997eb          I don't anonymously edit articles at all."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "BK6Sh8-Uz9ET",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CLEANING UP THE TEXT\n",
        "#Function to clean up the text\n",
        "def standardizetext(df, textfield):\n",
        "    df[textfield] = df[textfield].str.replace(r\"http\\S+\", \"\")\n",
        "    df[textfield] = df[textfield].str.replace(r\"http\", \"\")\n",
        "    df[textfield] = df[textfield].str.replace(r\"@\\S+\", \"\")\n",
        "    df[textfield] = df[textfield].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
        "    df[textfield] = df[textfield].str.replace(r\"@\", \"at\")\n",
        "    df[textfield] = df[textfield].str.lower()\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4LPhS45Lz9Ht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "4844a11d-9539-456f-a37e-1a392b514269"
      },
      "cell_type": "code",
      "source": [
        "traincomments.isnull().any()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               False\n",
              "comment_text     False\n",
              "toxic            False\n",
              "severe_toxic     False\n",
              "obscene          False\n",
              "threat           False\n",
              "insult           False\n",
              "identity_hate    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "l4lV4j5F3fEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "cd7fa173-4509-4145-8b6a-42cd745ead2e"
      },
      "cell_type": "code",
      "source": [
        "#Cleaning the train data and making the new CSV file -> train_clean_data.csv\n",
        "traincomments.fillna('_NA_')\n",
        "traincomments = standardizetext(traincomments, \"comment_text\")\n",
        "traincomments.to_csv(r\"~/.Data/traincleandata.csv\")\n",
        "traincomments.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>d'aww! he matches this background colour i'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>hey man, i'm really not trying to edit war  it...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>you, sir, are my hero  any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  explanation\\nwhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  d'aww! he matches this background colour i'm s...      0   \n",
              "2  000113f07ec002fd  hey man, i'm really not trying to edit war  it...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nmore\\ni can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  you, sir, are my hero  any chance you remember...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0             0        0       0       0              0  \n",
              "1             0        0       0       0              0  \n",
              "2             0        0       0       0              0  \n",
              "3             0        0       0       0              0  \n",
              "4             0        0       0       0              0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "lM9V7FljU7T7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "5b0ea65e-6e6b-4757-df64-3f0b02a4d189"
      },
      "cell_type": "code",
      "source": [
        "#Cleaning the test data and making the new CSV file -> test_clean_data.csv\n",
        "testcomments.fillna('_NA_')\n",
        "testcomments = standardizetext(testcomments, \"comment_text\")\n",
        "testcomments.to_csv(\"~/.Data/testcleandata.csv\")\n",
        "testcomments.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>yo bitch ja rule is more succesful then you'll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>from rfc    \\n\\n the title is fine as it is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n    sources    \\n\\n   zawe ashton on lap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>if you have a look back at the source, the in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>i don't anonymously edit articles at all</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text\n",
              "0  00001cee341fdb12  yo bitch ja rule is more succesful then you'll...\n",
              "1  0000247867823ef7     from rfc    \\n\\n the title is fine as it is...\n",
              "2  00013b17ad220c46  \" \\n\\n    sources    \\n\\n   zawe ashton on lap...\n",
              "3  00017563c3f7919a   if you have a look back at the source, the in...\n",
              "4  00017695ad8997eb          i don't anonymously edit articles at all "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "G5xxQtSu3fH_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0wLrJftc3fLS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TOKENIZING THE TEXT\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "cleantraincomments = pd.read_csv(r\"~/.Data/traincleandata.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Eg_bbW03fPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2bacb352-48ba-4766-a6cd-a94328d83543"
      },
      "cell_type": "code",
      "source": [
        "cleantraincomments['comment_text'] = cleantraincomments['comment_text'].astype('str')\n",
        "print(cleantraincomments['comment_text'].dtype)\n",
        "cleantraincomments['tokens'] = cleantraincomments['comment_text'].apply(tokenizer.tokenize)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tum1gKqU3fTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1145
        },
        "outputId": "d4f9e7a3-27bf-453f-aede-7a6732cb32ab"
      },
      "cell_type": "code",
      "source": [
        "cleantraincomments['tokens']"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         [explanation, why, the, edits, made, under, my...\n",
              "1         [d, aww, he, matches, this, background, colour...\n",
              "2         [hey, man, i, m, really, not, trying, to, edit...\n",
              "3         [more, i, can, t, make, any, real, suggestions...\n",
              "4         [you, sir, are, my, hero, any, chance, you, re...\n",
              "5         [congratulations, from, me, as, well, use, the...\n",
              "6         [cocksucker, before, you, piss, around, on, my...\n",
              "7         [your, vandalism, to, the, matt, shirvington, ...\n",
              "8         [sorry, if, the, word, nonsense, was, offensiv...\n",
              "9         [alignment, on, this, subject, and, which, are...\n",
              "10        [fair, use, rationale, for, image, wonju, jpg,...\n",
              "11        [bbq, be, a, man, and, lets, discuss, it, mayb...\n",
              "12        [hey, what, is, it, at, talk, what, is, it, an...\n",
              "13        [before, you, start, throwing, accusations, an...\n",
              "14        [oh, and, the, girl, above, started, her, argu...\n",
              "15        [juelz, santanas, age, in, 2002, juelz, santan...\n",
              "16        [bye, don, t, look, come, or, think, of, commi...\n",
              "17        [redirect, talk, voydan, pop, georgiev, cherno...\n",
              "18        [the, mitsurugi, point, made, no, sense, why, ...\n",
              "19        [don, t, mean, to, bother, you, i, see, that, ...\n",
              "20        [regarding, your, recent, edits, once, again, ...\n",
              "21        [good, to, know, about, me, yeah, i, m, studyi...\n",
              "22        [snowflakes, are, not, always, symmetrical, un...\n",
              "23        [the, signpost, 24, september, 2012, read, thi...\n",
              "24        [re, considering, 1st, paragraph, edit, i, don...\n",
              "25        [radial, symmetry, several, now, extinct, line...\n",
              "26        [there, s, no, need, to, apologize, a, wikiped...\n",
              "27        [yes, because, the, mother, of, the, child, in...\n",
              "28        [ok, but, it, will, take, a, bit, of, work, bu...\n",
              "29        [a, barnstar, for, you, the, real, life, barns...\n",
              "                                ...                        \n",
              "159541    [your, absurd, edits, your, absurd, edits, on,...\n",
              "159542    [maybe, he, s, got, better, things, to, do, th...\n",
              "159543    [scrap, that, it, does, meet, criteria, and, i...\n",
              "159544                              [you, could, do, worse]\n",
              "159545    [7, march, 2011, utc, are, you, also, user, bm...\n",
              "159546    [hey, listen, don, t, you, ever, delete, my, e...\n",
              "159547                       [thank, you, very, very, much]\n",
              "159548                      [talkback, 15, september, 2012]\n",
              "159549                         [2005, utc, 06, 35, 31, mar]\n",
              "159550    [i, agree, on, another, note, lil, wayne, is, ...\n",
              "159551    [while, about, half, the, references, are, fro...\n",
              "159552    [prague, spring, i, think, that, prague, sprin...\n",
              "159553    [i, see, this, as, having, been, merged, undoi...\n",
              "159554    [and, i, m, going, to, keep, posting, the, stu...\n",
              "159555    [how, come, when, you, download, that, mp3, it...\n",
              "159556    [i, ll, be, on, irc, too, if, you, have, a, mo...\n",
              "159557    [it, is, my, opinion, that, that, happens, to,...\n",
              "159558    [please, stop, removing, content, from, wikipe...\n",
              "159559    [image, barack, obama, mother, jpg, listed, fo...\n",
              "159560    [editing, of, article, without, consensus, rem...\n",
              "159561    [no, he, did, not, read, it, again, i, would, ...\n",
              "159562    [auto, guides, and, the, motoring, press, are,...\n",
              "159563    [please, identify, what, part, of, blp, applie...\n",
              "159564    [catalan, independentism, is, the, social, mov...\n",
              "159565    [the, numbers, in, parentheses, are, the, addi...\n",
              "159566    [and, for, the, second, time, of, asking, when...\n",
              "159567    [you, should, be, ashamed, of, yourself, that,...\n",
              "159568    [spitzer, umm, theres, no, actual, article, fo...\n",
              "159569    [and, it, looks, like, it, was, actually, you,...\n",
              "159570    [and, i, really, don, t, think, you, understan...\n",
              "Name: tokens, Length: 159571, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "DnwcHYJf7Kyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "bd668f43-84ac-469c-9021-429b6a47e436"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "oYrAy_EW3fXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "1a370c55-663c-48d7-d23b-dca73599fe2a"
      },
      "cell_type": "code",
      "source": [
        "#Deleting the stop words\n",
        "cleantraincomments[\"tokens\"] = cleantraincomments[\"tokens\"].apply(\n",
        "    lambda vec: [word for word in vec if word not in stopwords.words('english')])\n",
        "cleantraincomments.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[explanation, edits, made, username, hardcore,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>d'aww! he matches this background colour i'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[aww, matches, background, colour, seemingly, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>hey man, i'm really not trying to edit war  it...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[make, real, suggestions, improvement, wondere...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>you, sir, are my hero  any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[sir, hero, chance, remember, page]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                id  \\\n",
              "0           0  0000997932d777bf   \n",
              "1           1  000103f0d9cfb60f   \n",
              "2           2  000113f07ec002fd   \n",
              "3           3  0001b41b1c6bb37e   \n",
              "4           4  0001d958c54c6e35   \n",
              "\n",
              "                                        comment_text  toxic  severe_toxic  \\\n",
              "0  explanation\\nwhy the edits made under my usern...      0             0   \n",
              "1  d'aww! he matches this background colour i'm s...      0             0   \n",
              "2  hey man, i'm really not trying to edit war  it...      0             0   \n",
              "3  \"\\nmore\\ni can't make any real suggestions on ...      0             0   \n",
              "4  you, sir, are my hero  any chance you remember...      0             0   \n",
              "\n",
              "   obscene  threat  insult  identity_hate  \\\n",
              "0        0       0       0              0   \n",
              "1        0       0       0              0   \n",
              "2        0       0       0              0   \n",
              "3        0       0       0              0   \n",
              "4        0       0       0              0   \n",
              "\n",
              "                                              tokens  \n",
              "0  [explanation, edits, made, username, hardcore,...  \n",
              "1  [aww, matches, background, colour, seemingly, ...  \n",
              "2  [hey, man, really, trying, edit, war, guy, con...  \n",
              "3  [make, real, suggestions, improvement, wondere...  \n",
              "4                [sir, hero, chance, remember, page]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "metadata": {
        "id": "NQCzqdpN7K-Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cleantraincomments.to_csv(r'~/.Data/trainCleanDatatokens.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vVoInM0IQQnS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cleantraincomments = pd.read_csv(r'~/.Data/trainCleanDatatokens.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oX16uxSrTR1C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cleantraincomments['comment_text'] = cleantraincomments['comment_text'].astype('str')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zis7wSSIQduN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "a368abd5-9ad5-4671-96ef-c880e539d7bb"
      },
      "cell_type": "code",
      "source": [
        "cleantraincomments.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['explanation', 'edits', 'made', 'username', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>d'aww! he matches this background colour i'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['aww', 'matches', 'background', 'colour', 'se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>hey man, i'm really not trying to edit war  it...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['hey', 'man', 'really', 'trying', 'edit', 'wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['make', 'real', 'suggestions', 'improvement',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>you, sir, are my hero  any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['sir', 'hero', 'chance', 'remember', 'page']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1                id  \\\n",
              "0           0             0  0000997932d777bf   \n",
              "1           1             1  000103f0d9cfb60f   \n",
              "2           2             2  000113f07ec002fd   \n",
              "3           3             3  0001b41b1c6bb37e   \n",
              "4           4             4  0001d958c54c6e35   \n",
              "\n",
              "                                        comment_text  toxic  severe_toxic  \\\n",
              "0  explanation\\nwhy the edits made under my usern...      0             0   \n",
              "1  d'aww! he matches this background colour i'm s...      0             0   \n",
              "2  hey man, i'm really not trying to edit war  it...      0             0   \n",
              "3  \"\\nmore\\ni can't make any real suggestions on ...      0             0   \n",
              "4  you, sir, are my hero  any chance you remember...      0             0   \n",
              "\n",
              "   obscene  threat  insult  identity_hate  \\\n",
              "0        0       0       0              0   \n",
              "1        0       0       0              0   \n",
              "2        0       0       0              0   \n",
              "3        0       0       0              0   \n",
              "4        0       0       0              0   \n",
              "\n",
              "                                              tokens  \n",
              "0  ['explanation', 'edits', 'made', 'username', '...  \n",
              "1  ['aww', 'matches', 'background', 'colour', 'se...  \n",
              "2  ['hey', 'man', 'really', 'trying', 'edit', 'wa...  \n",
              "3  ['make', 'real', 'suggestions', 'improvement',...  \n",
              "4      ['sir', 'hero', 'chance', 'remember', 'page']  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "VdaR3huU_xPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "997aa318-25ae-418e-dc33-db6384c1e8d2"
      },
      "cell_type": "code",
      "source": [
        "!head ~/.Data/trainCleanDatatokens.csv"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ",Unnamed: 0,id,comment_text,toxic,severe_toxic,obscene,threat,insult,identity_hate,tokens\n",
            "0,0,0000997932d777bf,\"explanation\n",
            "why the edits made under my username hardcore metallica fan were reverted? they weren't vandalisms, just closure on some gas after i voted at new york dolls fac  and please don't remove the template from the talk page since i'm retired now 89 205 38 27\",0,0,0,0,0,0,\"['explanation', 'edits', 'made', 'username', 'hardcore', 'metallica', 'fan', 'reverted', 'vandalisms', 'closure', 'gas', 'voted', 'new', 'york', 'dolls', 'fac', 'please', 'remove', 'template', 'talk', 'page', 'since', 'retired', '89', '205', '38', '27']\"\n",
            "1,1,000103f0d9cfb60f,\"d'aww! he matches this background colour i'm seemingly stuck with  thanks   (talk) 21 51, january 11, 2016 (utc)\",0,0,0,0,0,0,\"['aww', 'matches', 'background', 'colour', 'seemingly', 'stuck', 'thanks', 'talk', '21', '51', 'january', '11', '2016', 'utc']\"\n",
            "2,2,000113f07ec002fd,\"hey man, i'm really not trying to edit war  it's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page  he seems to care more about the formatting than the actual info \",0,0,0,0,0,0,\"['hey', 'man', 'really', 'trying', 'edit', 'war', 'guy', 'constantly', 'removing', 'relevant', 'information', 'talking', 'edits', 'instead', 'talk', 'page', 'seems', 'care', 'formatting', 'actual', 'info']\"\n",
            "3,3,0001b41b1c6bb37e,\"\"\"\n",
            "more\n",
            "i can't make any real suggestions on improvement   i wondered if the section statistics should be later on, or a subsection of \"\"\"\"types of accidents\"\"\"\"   i think the references may need tidying so that they are all in the exact same format ie date format etc  i can do that later on, if no one else does first   if you have any preferences for formatting style on references or want to do it yourself please let me know \n",
            "\n",
            "there appears to be a backlog on articles for review so i guess there may be a delay until a reviewer turns up  it's listed in the relevant form eg wikipedia good_article_nominations transport  \"\"\",0,0,0,0,0,0,\"['make', 'real', 'suggestions', 'improvement', 'wondered', 'section', 'statistics', 'later', 'subsection', 'types', 'accidents', 'think', 'references', 'may', 'need', 'tidying', 'exact', 'format', 'ie', 'date', 'format', 'etc', 'later', 'one', 'else', 'first', 'preferences', 'formatting', 'style', 'references', 'want', 'please', 'let', 'know', 'appears', 'backlog', 'articles', 'review', 'guess', 'may', 'delay', 'reviewer', 'turns', 'listed', 'relevant', 'form', 'eg', 'wikipedia', 'good_article_nominations', 'transport']\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OcGkFjlOUQag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "ede5c295-c87a-4437-e08d-27be4407c86a"
      },
      "cell_type": "code",
      "source": [
        "# similary cleaning the test comment data\n",
        "cleantestcomments = pd.read_csv(r\"~/.Data/testcleandata.csv\")\n",
        "cleantestcomments['comment_text'] = cleantestcomments['comment_text'].astype('str') \n",
        "cleantestcomments.dtypes\n",
        "cleantestcomments[\"tokens\"] = cleantestcomments[\"comment_text\"].apply(tokenizer.tokenize)\n",
        "cleantestcomments[\"tokens\"] = cleantestcomments[\"tokens\"].apply(lambda vec: [word for word in vec if word not in stopwords.words('english')])\n",
        "cleantestcomments.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>yo bitch ja rule is more succesful then you'll...</td>\n",
              "      <td>[yo, bitch, ja, rule, succesful, ever, whats, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>from rfc    \\n\\n the title is fine as it is...</td>\n",
              "      <td>[rfc, title, fine, imo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>\" \\n\\n    sources    \\n\\n   zawe ashton on lap...</td>\n",
              "      <td>[sources, zawe, ashton, lapland]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>if you have a look back at the source, the in...</td>\n",
              "      <td>[look, back, source, information, updated, cor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>i don't anonymously edit articles at all</td>\n",
              "      <td>[anonymously, edit, articles]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                id  \\\n",
              "0           0  00001cee341fdb12   \n",
              "1           1  0000247867823ef7   \n",
              "2           2  00013b17ad220c46   \n",
              "3           3  00017563c3f7919a   \n",
              "4           4  00017695ad8997eb   \n",
              "\n",
              "                                        comment_text  \\\n",
              "0  yo bitch ja rule is more succesful then you'll...   \n",
              "1     from rfc    \\n\\n the title is fine as it is...   \n",
              "2  \" \\n\\n    sources    \\n\\n   zawe ashton on lap...   \n",
              "3   if you have a look back at the source, the in...   \n",
              "4          i don't anonymously edit articles at all    \n",
              "\n",
              "                                              tokens  \n",
              "0  [yo, bitch, ja, rule, succesful, ever, whats, ...  \n",
              "1                            [rfc, title, fine, imo]  \n",
              "2                   [sources, zawe, ashton, lapland]  \n",
              "3  [look, back, source, information, updated, cor...  \n",
              "4                      [anonymously, edit, articles]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "ERMgG3kJcdc0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cleantestcomments.to_csv(r'~/.Data/testCleanDatatokens.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xQhWbTP0Uf05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "056a3981-afe0-4d3e-e983-3b09f4f9dbf2"
      },
      "cell_type": "code",
      "source": [
        "!ls ~/.Data"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GoogleNews-vectors-negative300.bin.gz\t      test_labels.csv.zip\n",
            "googles-trained-word2vec-model-in-python.zip  traincleandata.csv\n",
            "sample_submission.csv.zip\t\t      trainCleanDatatokens.csv\n",
            "test.csv\t\t\t\t      train.csv\n",
            "test.csv.zip\t\t\t\t      train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0hmpF4PuFpVK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "b1b112d3-f49f-49b3-ff31-42e87384b7a5"
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "# import gensim"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/f3/37504f07651330ddfdefa631ca5246974a60d0908216539efda842fd080f/gensim-3.5.0-cp36-cp36m-manylinux1_x86_64.whl (23.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.5MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/cf/3d/5f3a9a296d0ba8e00e263a8dee76762076b9eb5ddc254ccaa834651c8d65/smart_open-1.6.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.5)\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 12.5MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/bf/e287410bc16b38b3e02853b7ca8af0f602a5075af5c8c77f50ec5339f034/boto3-1.9.0-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 24.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.8.24)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting botocore<1.13.0,>=1.12.0 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/3f/fecf78a1f4a495531eaab3cb386a33a32ae26371261bf39e030003dc05de/botocore-1.12.0-py2.py3-none-any.whl (4.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.7MB 899kB/s \n",
            "\u001b[?25hCollecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 17.7MB/s \n",
            "\u001b[?25hCollecting docutils>=0.10 (from botocore<1.13.0,>=1.12.0->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 22.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.0->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Building wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/73/f1/9b/ccf93d4ba073b6f79b1ed9df68ab5ce048d8136d0efcf90b30\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.49.0 boto3-1.9.0 botocore-1.12.0 bz2file-0.98 docutils-0.14 gensim-3.5.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_tW_YW2wF5o6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BHGT5sEmQlWO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "gbjzTb1O_xV9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ec90cf5c-37ef-4b3d-968d-00e0dc92dcec"
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d umbertogriffo/googles-trained-word2vec-model-in-python"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading googles-trained-word2vec-model-in-python.zip to /content\n",
            " 99% 1.52G/1.53G [00:12<00:00, 158MB/s]\n",
            "100% 1.53G/1.53G [00:12<00:00, 129MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bRaBZoSmGSVj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv GoogleNews-vectors-negative300.bin.gz ~/.Data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "081_VHSYHtZH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "word2vecpath = r\"~/.Data/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oAGKFIh9_xbD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vecpath, binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OPkdOOhLPDzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cdf8ee2d-3ba1-4b89-cc18-ecd8954921da"
      },
      "cell_type": "code",
      "source": [
        "word2vec.vectors.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "RSdoY6VRPPIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "56eb1ac1-45e6-4e99-ec33-f264c551d2f6"
      },
      "cell_type": "code",
      "source": [
        "# word2vec.similar_by_word('name')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-17c56c21fe86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilar_by_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'word2vec' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4PUdxVa__xeJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getaverageword2vec(tokenslist, vector, generatemissing=False, k=300):\n",
        "    if len(tokenslist)<1:\n",
        "        return np.zeros(k)\n",
        "    if generatemissing:\n",
        "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokenslist]\n",
        "    else:\n",
        "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokenslist]\n",
        "    length = len(vectorized)\n",
        "    summed = np.sum(vectorized, axis=0)\n",
        "    averaged = np.divide(summed, length)\n",
        "    return averaged\n",
        "#GETTING EMBEDDINGS\n",
        "def getword2vecembeddings(vectors, cleancomments, generatemissing=False):\n",
        "    embeddings = cleancomments['tokens'].apply(lambda x: getaverageword2vec(x, vectors, \n",
        "                                                                          generatemissing=generatemissing))\n",
        "    return list(embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nvT-UwWHLYCX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YmPTuLLI_xi4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TRAIN EMBEDDING\n",
        "trainingembeddings = getword2vecembeddings(word2vec, cleantraincomments, generatemissing=True)\n",
        "tokenizer = Tokenizer(num_words=MAXVOCABSIZE, lower=True, char_level=False)\n",
        "tokenizer.fit_on_texts(cleantraincomments[\"comment_text\"].tolist())\n",
        "trainingsequences = tokenizer.texts_to_sequences(cleantraincomments[\"comment_text\"].tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D65qpIYI_xmc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ec9a8e9-6df2-4fff-8346-f10da6a5f429"
      },
      "cell_type": "code",
      "source": [
        "trainwordindex  = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(trainwordindex))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 190289 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7oBEjcQj_xxq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18217
        },
        "outputId": "ff1452b3-166d-41d9-a9c2-feb6f284ac13"
      },
      "cell_type": "code",
      "source": [
        "trainwordindex"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'to': 2,\n",
              " 'of': 3,\n",
              " 'and': 4,\n",
              " 'a': 5,\n",
              " 'you': 6,\n",
              " 'i': 7,\n",
              " 'is': 8,\n",
              " 'that': 9,\n",
              " 'in': 10,\n",
              " 'it': 11,\n",
              " 'for': 12,\n",
              " 'this': 13,\n",
              " 'not': 14,\n",
              " 'on': 15,\n",
              " 'be': 16,\n",
              " 'as': 17,\n",
              " 'are': 18,\n",
              " 'have': 19,\n",
              " 'your': 20,\n",
              " 'with': 21,\n",
              " 'if': 22,\n",
              " 'article': 23,\n",
              " 'was': 24,\n",
              " 'or': 25,\n",
              " 'but': 26,\n",
              " 'page': 27,\n",
              " 'my': 28,\n",
              " 'an': 29,\n",
              " 'wikipedia': 30,\n",
              " 'from': 31,\n",
              " 'by': 32,\n",
              " 'do': 33,\n",
              " 'at': 34,\n",
              " 'me': 35,\n",
              " 'about': 36,\n",
              " 'talk': 37,\n",
              " 'so': 38,\n",
              " 'what': 39,\n",
              " 'can': 40,\n",
              " 'there': 41,\n",
              " 'all': 42,\n",
              " 'has': 43,\n",
              " 'will': 44,\n",
              " 'please': 45,\n",
              " 'no': 46,\n",
              " 'would': 47,\n",
              " 'one': 48,\n",
              " 'like': 49,\n",
              " 'just': 50,\n",
              " 'they': 51,\n",
              " 'he': 52,\n",
              " 'which': 53,\n",
              " 'any': 54,\n",
              " 'been': 55,\n",
              " 'should': 56,\n",
              " 'more': 57,\n",
              " 'we': 58,\n",
              " \"don't\": 59,\n",
              " 'other': 60,\n",
              " 'some': 61,\n",
              " 'who': 62,\n",
              " 'here': 63,\n",
              " 'see': 64,\n",
              " 'his': 65,\n",
              " 'also': 66,\n",
              " 'think': 67,\n",
              " 'because': 68,\n",
              " 'know': 69,\n",
              " 'how': 70,\n",
              " 'edit': 71,\n",
              " 'am': 72,\n",
              " 'why': 73,\n",
              " \"i'm\": 74,\n",
              " 'up': 75,\n",
              " 'people': 76,\n",
              " 'only': 77,\n",
              " \"it's\": 78,\n",
              " 'out': 79,\n",
              " 'use': 80,\n",
              " 'articles': 81,\n",
              " 'when': 82,\n",
              " 'then': 83,\n",
              " 'time': 84,\n",
              " 'may': 85,\n",
              " 'were': 86,\n",
              " 'did': 87,\n",
              " 'them': 88,\n",
              " 'now': 89,\n",
              " 'being': 90,\n",
              " 'their': 91,\n",
              " 'user': 92,\n",
              " 'thanks': 93,\n",
              " 'than': 94,\n",
              " 'get': 95,\n",
              " 'even': 96,\n",
              " 'make': 97,\n",
              " 'good': 98,\n",
              " 'well': 99,\n",
              " 'had': 100,\n",
              " 'information': 101,\n",
              " 'very': 102,\n",
              " 'does': 103,\n",
              " 'could': 104,\n",
              " 'want': 105,\n",
              " 'deletion': 106,\n",
              " 'its': 107,\n",
              " 'sources': 108,\n",
              " 'such': 109,\n",
              " 'way': 110,\n",
              " 'name': 111,\n",
              " 'first': 112,\n",
              " 'these': 113,\n",
              " 'pages': 114,\n",
              " 'wp': 115,\n",
              " 'help': 116,\n",
              " 'image': 117,\n",
              " 'new': 118,\n",
              " 'go': 119,\n",
              " 'fuck': 120,\n",
              " 'editing': 121,\n",
              " 'source': 122,\n",
              " 'need': 123,\n",
              " 'say': 124,\n",
              " 'section': 125,\n",
              " 'again': 126,\n",
              " 'where': 127,\n",
              " 'edits': 128,\n",
              " 'thank': 129,\n",
              " 'made': 130,\n",
              " 'many': 131,\n",
              " 'much': 132,\n",
              " 'deleted': 133,\n",
              " 'used': 134,\n",
              " 'really': 135,\n",
              " 'most': 136,\n",
              " 'discussion': 137,\n",
              " 'same': 138,\n",
              " 'find': 139,\n",
              " 'into': 140,\n",
              " 'those': 141,\n",
              " 'work': 142,\n",
              " \"i've\": 143,\n",
              " 'right': 144,\n",
              " 'after': 145,\n",
              " 'since': 146,\n",
              " 'point': 147,\n",
              " 'before': 148,\n",
              " 'add': 149,\n",
              " 'read': 150,\n",
              " 'look': 151,\n",
              " 'take': 152,\n",
              " 'still': 153,\n",
              " 'him': 154,\n",
              " 'over': 155,\n",
              " 'two': 156,\n",
              " 'back': 157,\n",
              " 'fact': 158,\n",
              " 'someone': 159,\n",
              " 'hi': 160,\n",
              " 'too': 161,\n",
              " 'said': 162,\n",
              " 'own': 163,\n",
              " 'block': 164,\n",
              " 'going': 165,\n",
              " 'link': 166,\n",
              " 'list': 167,\n",
              " 'something': 168,\n",
              " 'blocked': 169,\n",
              " 'stop': 170,\n",
              " '2': 171,\n",
              " 'content': 172,\n",
              " \"you're\": 173,\n",
              " 'without': 174,\n",
              " '1': 175,\n",
              " 'under': 176,\n",
              " 'our': 177,\n",
              " 'added': 178,\n",
              " 'history': 179,\n",
              " 'utc': 180,\n",
              " 'her': 181,\n",
              " 'removed': 182,\n",
              " 'editors': 183,\n",
              " 'another': 184,\n",
              " 'might': 185,\n",
              " 'yourself': 186,\n",
              " 'note': 187,\n",
              " 'welcome': 188,\n",
              " 'vandalism': 189,\n",
              " 'free': 190,\n",
              " 'however': 191,\n",
              " 'place': 192,\n",
              " 'sure': 193,\n",
              " 'never': 194,\n",
              " 'case': 195,\n",
              " 'off': 196,\n",
              " 'reason': 197,\n",
              " \"doesn't\": 198,\n",
              " 'done': 199,\n",
              " 'put': 200,\n",
              " 'comment': 201,\n",
              " 'better': 202,\n",
              " 'personal': 203,\n",
              " 'seems': 204,\n",
              " 'ask': 205,\n",
              " 'wiki': 206,\n",
              " 'using': 207,\n",
              " \"that's\": 208,\n",
              " 'us': 209,\n",
              " 'feel': 210,\n",
              " 'actually': 211,\n",
              " 'question': 212,\n",
              " 'while': 213,\n",
              " 'believe': 214,\n",
              " 'anything': 215,\n",
              " 'u': 216,\n",
              " 's': 217,\n",
              " 'links': 218,\n",
              " 'person': 219,\n",
              " 'both': 220,\n",
              " 'she': 221,\n",
              " 'things': 222,\n",
              " 'policy': 223,\n",
              " 'part': 224,\n",
              " 'comments': 225,\n",
              " 'hope': 226,\n",
              " 'best': 227,\n",
              " '3': 228,\n",
              " 'against': 229,\n",
              " 'thing': 230,\n",
              " 'already': 231,\n",
              " 'questions': 232,\n",
              " 'change': 233,\n",
              " 'nothing': 234,\n",
              " \"can't\": 235,\n",
              " \"didn't\": 236,\n",
              " \"i'll\": 237,\n",
              " 'keep': 238,\n",
              " 'wrong': 239,\n",
              " 'copyright': 240,\n",
              " 'subject': 241,\n",
              " 'though': 242,\n",
              " 'problem': 243,\n",
              " 'little': 244,\n",
              " 'remove': 245,\n",
              " 'must': 246,\n",
              " 'tag': 247,\n",
              " 'long': 248,\n",
              " 'above': 249,\n",
              " 'trying': 250,\n",
              " 'understand': 251,\n",
              " 'anyone': 252,\n",
              " 'sorry': 253,\n",
              " 'last': 254,\n",
              " 'few': 255,\n",
              " 'give': 256,\n",
              " 'speedy': 257,\n",
              " 'reliable': 258,\n",
              " 'others': 259,\n",
              " 'world': 260,\n",
              " 'agree': 261,\n",
              " 'issue': 262,\n",
              " 'rather': 263,\n",
              " 'let': 264,\n",
              " 'years': 265,\n",
              " 'editor': 266,\n",
              " 'come': 267,\n",
              " 'fair': 268,\n",
              " 'different': 269,\n",
              " 'style': 270,\n",
              " 'english': 271,\n",
              " 'text': 272,\n",
              " 'making': 273,\n",
              " 'reference': 274,\n",
              " 'references': 275,\n",
              " 'non': 276,\n",
              " 'try': 277,\n",
              " 'mean': 278,\n",
              " 'great': 279,\n",
              " 'doing': 280,\n",
              " 'found': 281,\n",
              " 'continue': 282,\n",
              " 'leave': 283,\n",
              " 'state': 284,\n",
              " 'word': 285,\n",
              " 'got': 286,\n",
              " 'original': 287,\n",
              " 'day': 288,\n",
              " 'life': 289,\n",
              " 'oh': 290,\n",
              " 'post': 291,\n",
              " \"isn't\": 292,\n",
              " 'probably': 293,\n",
              " 'created': 294,\n",
              " 'every': 295,\n",
              " 'says': 296,\n",
              " 'e': 297,\n",
              " 'adding': 298,\n",
              " 'either': 299,\n",
              " 'hello': 300,\n",
              " 'consensus': 301,\n",
              " 'check': 302,\n",
              " 'top': 303,\n",
              " 'show': 304,\n",
              " 'simply': 305,\n",
              " 'delete': 306,\n",
              " 'site': 307,\n",
              " 'least': 308,\n",
              " 'yes': 309,\n",
              " 'ip': 310,\n",
              " 'far': 311,\n",
              " 'opinion': 312,\n",
              " 'etc': 313,\n",
              " 'example': 314,\n",
              " 'else': 315,\n",
              " 'called': 316,\n",
              " 'request': 317,\n",
              " 'notable': 318,\n",
              " 'through': 319,\n",
              " 'view': 320,\n",
              " 'enough': 321,\n",
              " 'war': 322,\n",
              " 'contributions': 323,\n",
              " 'around': 324,\n",
              " 're': 325,\n",
              " 'write': 326,\n",
              " 'book': 327,\n",
              " 'reverted': 328,\n",
              " 't': 329,\n",
              " 'yet': 330,\n",
              " 'between': 331,\n",
              " 'matter': 332,\n",
              " 'real': 333,\n",
              " 'down': 334,\n",
              " 'material': 335,\n",
              " 'thought': 336,\n",
              " 'images': 337,\n",
              " 'encyclopedia': 338,\n",
              " 'old': 339,\n",
              " 'given': 340,\n",
              " 'shit': 341,\n",
              " 'message': 342,\n",
              " 'account': 343,\n",
              " 'having': 344,\n",
              " 'users': 345,\n",
              " 'evidence': 346,\n",
              " 'admin': 347,\n",
              " 'clearly': 348,\n",
              " 'support': 349,\n",
              " 'language': 350,\n",
              " 'hate': 351,\n",
              " 'maybe': 352,\n",
              " 'needs': 353,\n",
              " 'ever': 354,\n",
              " 'revert': 355,\n",
              " 'lot': 356,\n",
              " 'nigger': 357,\n",
              " 'tell': 358,\n",
              " 'important': 359,\n",
              " 'media': 360,\n",
              " 'instead': 361,\n",
              " '5': 362,\n",
              " 'seem': 363,\n",
              " 'clear': 364,\n",
              " 'states': 365,\n",
              " 'correct': 366,\n",
              " 'number': 367,\n",
              " 'saying': 368,\n",
              " 'always': 369,\n",
              " '4': 370,\n",
              " 'further': 371,\n",
              " 'quite': 372,\n",
              " 'perhaps': 373,\n",
              " 'bad': 374,\n",
              " 'pov': 375,\n",
              " 'ass': 376,\n",
              " 'template': 377,\n",
              " 'fucking': 378,\n",
              " 'written': 379,\n",
              " 'until': 380,\n",
              " 'c': 381,\n",
              " 'term': 382,\n",
              " 'true': 383,\n",
              " 'bit': 384,\n",
              " 'claim': 385,\n",
              " 'criteria': 386,\n",
              " 'whether': 387,\n",
              " 'once': 388,\n",
              " 'based': 389,\n",
              " 'research': 390,\n",
              " 'review': 391,\n",
              " \"i'd\": 392,\n",
              " 'consider': 393,\n",
              " 'times': 394,\n",
              " 'guidelines': 395,\n",
              " 'website': 396,\n",
              " 'version': 397,\n",
              " 'getting': 398,\n",
              " 'three': 399,\n",
              " 'rules': 400,\n",
              " 'mention': 401,\n",
              " 'title': 402,\n",
              " 'year': 403,\n",
              " 'cannot': 404,\n",
              " 'considered': 405,\n",
              " 'several': 406,\n",
              " 'suck': 407,\n",
              " 'makes': 408,\n",
              " 'words': 409,\n",
              " \"there's\": 410,\n",
              " 'changes': 411,\n",
              " 'notice': 412,\n",
              " 'address': 413,\n",
              " 'left': 414,\n",
              " 'following': 415,\n",
              " 'group': 416,\n",
              " 'listed': 417,\n",
              " 'second': 418,\n",
              " 'idea': 419,\n",
              " 'current': 420,\n",
              " 'means': 421,\n",
              " 'date': 422,\n",
              " 'hey': 423,\n",
              " 'facts': 424,\n",
              " 'man': 425,\n",
              " 'regarding': 426,\n",
              " 'each': 427,\n",
              " 'general': 428,\n",
              " 'american': 429,\n",
              " 'main': 430,\n",
              " 'possible': 431,\n",
              " 'mentioned': 432,\n",
              " 'statement': 433,\n",
              " 'course': 434,\n",
              " 'whole': 435,\n",
              " 'kind': 436,\n",
              " 'start': 437,\n",
              " 'include': 438,\n",
              " 'known': 439,\n",
              " 'topic': 440,\n",
              " 'create': 441,\n",
              " 'issues': 442,\n",
              " 'seen': 443,\n",
              " '10': 444,\n",
              " 'care': 445,\n",
              " 'end': 446,\n",
              " 'less': 447,\n",
              " 'call': 448,\n",
              " 'ok': 449,\n",
              " 'related': 450,\n",
              " 'attack': 451,\n",
              " 'suggest': 452,\n",
              " 'die': 453,\n",
              " 'sense': 454,\n",
              " 'including': 455,\n",
              " 'happy': 456,\n",
              " 'big': 457,\n",
              " 'contribs': 458,\n",
              " 'dont': 459,\n",
              " 'notability': 460,\n",
              " 'info': 461,\n",
              " 'myself': 462,\n",
              " 'move': 463,\n",
              " '2005': 464,\n",
              " 'anyway': 465,\n",
              " 'sentence': 466,\n",
              " 'love': 467,\n",
              " 'redirect': 468,\n",
              " 'provide': 469,\n",
              " 'days': 470,\n",
              " 'jpg': 471,\n",
              " \"wikipedia's\": 472,\n",
              " 'line': 473,\n",
              " 'category': 474,\n",
              " 'changed': 475,\n",
              " 'explain': 476,\n",
              " 'mind': 477,\n",
              " 'four': 478,\n",
              " 'project': 479,\n",
              " 'neutral': 480,\n",
              " 'started': 481,\n",
              " 'school': 482,\n",
              " 'appropriate': 483,\n",
              " 'next': 484,\n",
              " 'included': 485,\n",
              " 'looking': 486,\n",
              " 'interest': 487,\n",
              " 'although': 488,\n",
              " 'specific': 489,\n",
              " 'relevant': 490,\n",
              " 'community': 491,\n",
              " 'gay': 492,\n",
              " 'removing': 493,\n",
              " 'picture': 494,\n",
              " 'warning': 495,\n",
              " 'sign': 496,\n",
              " 'per': 497,\n",
              " 'answer': 498,\n",
              " 'order': 499,\n",
              " 'recent': 500,\n",
              " 'full': 501,\n",
              " 'fat': 502,\n",
              " 'away': 503,\n",
              " 'later': 504,\n",
              " 'writing': 505,\n",
              " 'policies': 506,\n",
              " \"you've\": 507,\n",
              " 'discuss': 508,\n",
              " 'live': 509,\n",
              " 'summary': 510,\n",
              " 'claims': 511,\n",
              " '6': 512,\n",
              " 'wish': 513,\n",
              " 'interested': 514,\n",
              " 'wrote': 515,\n",
              " 'public': 516,\n",
              " 'especially': 517,\n",
              " 'taken': 518,\n",
              " 'able': 519,\n",
              " 'currently': 520,\n",
              " 'file': 521,\n",
              " 'faith': 522,\n",
              " 'attacks': 523,\n",
              " 'god': 524,\n",
              " 'position': 525,\n",
              " 'background': 526,\n",
              " 'color': 527,\n",
              " 'stuff': 528,\n",
              " 'self': 529,\n",
              " 'appears': 530,\n",
              " 'd': 531,\n",
              " 'names': 532,\n",
              " 'during': 533,\n",
              " 'according': 534,\n",
              " '0': 535,\n",
              " 'below': 536,\n",
              " 'wanted': 537,\n",
              " 'completely': 538,\n",
              " 'anti': 539,\n",
              " 'itself': 540,\n",
              " 'single': 541,\n",
              " 'certainly': 542,\n",
              " 'web': 543,\n",
              " 'within': 544,\n",
              " '7': 545,\n",
              " 'report': 546,\n",
              " 'pig': 547,\n",
              " 'common': 548,\n",
              " 'country': 549,\n",
              " 'lead': 550,\n",
              " 'official': 551,\n",
              " '20': 552,\n",
              " 'news': 553,\n",
              " 'published': 554,\n",
              " 'unless': 555,\n",
              " 'hard': 556,\n",
              " 'everyone': 557,\n",
              " '2006': 558,\n",
              " 'pretty': 559,\n",
              " 'cunt': 560,\n",
              " 'nice': 561,\n",
              " 'b': 562,\n",
              " 'involved': 563,\n",
              " 'high': 564,\n",
              " 'looks': 565,\n",
              " 'everything': 566,\n",
              " 'future': 567,\n",
              " 'process': 568,\n",
              " '24': 569,\n",
              " 'obviously': 570,\n",
              " 'due': 571,\n",
              " 'truth': 572,\n",
              " 'edited': 573,\n",
              " 'reading': 574,\n",
              " 'nor': 575,\n",
              " 'p': 576,\n",
              " '100': 577,\n",
              " 'came': 578,\n",
              " 'remember': 579,\n",
              " 'therefore': 580,\n",
              " 'small': 581,\n",
              " '8': 582,\n",
              " 'admins': 583,\n",
              " 'party': 584,\n",
              " 'stay': 585,\n",
              " '11': 586,\n",
              " 'sandbox': 587,\n",
              " 'learn': 588,\n",
              " \"won't\": 589,\n",
              " 'whatever': 590,\n",
              " 'city': 591,\n",
              " \"wasn't\": 592,\n",
              " 'past': 593,\n",
              " 'administrator': 594,\n",
              " 'response': 595,\n",
              " 'entry': 596,\n",
              " 'political': 597,\n",
              " 'ago': 598,\n",
              " 'game': 599,\n",
              " 'asked': 600,\n",
              " 'talking': 601,\n",
              " 'united': 602,\n",
              " 'quote': 603,\n",
              " 'paragraph': 604,\n",
              " 'similar': 605,\n",
              " 'power': 606,\n",
              " \"he's\": 607,\n",
              " 'placed': 608,\n",
              " 'argument': 609,\n",
              " 'today': 610,\n",
              " 'system': 611,\n",
              " 'useful': 612,\n",
              " 'posted': 613,\n",
              " 'stupid': 614,\n",
              " 'working': 615,\n",
              " 'exactly': 616,\n",
              " 'reverting': 617,\n",
              " 'books': 618,\n",
              " 'took': 619,\n",
              " 'guy': 620,\n",
              " 'deleting': 621,\n",
              " 'guess': 622,\n",
              " 'regards': 623,\n",
              " 'government': 624,\n",
              " '2007': 625,\n",
              " 'dispute': 626,\n",
              " '12': 627,\n",
              " 'sex': 628,\n",
              " 'side': 629,\n",
              " '2008': 630,\n",
              " 'false': 631,\n",
              " 'along': 632,\n",
              " 'noticed': 633,\n",
              " 'reasons': 634,\n",
              " 'major': 635,\n",
              " 'appreciate': 636,\n",
              " 'knowledge': 637,\n",
              " 'lol': 638,\n",
              " 'm': 639,\n",
              " 'british': 640,\n",
              " 'penis': 641,\n",
              " '15': 642,\n",
              " 'particular': 643,\n",
              " 'banned': 644,\n",
              " 'form': 645,\n",
              " 'five': 646,\n",
              " 'fish': 647,\n",
              " 'law': 648,\n",
              " 'national': 649,\n",
              " 'provided': 650,\n",
              " 'almost': 651,\n",
              " 'tried': 652,\n",
              " 'search': 653,\n",
              " 'npov': 654,\n",
              " 'wikiproject': 655,\n",
              " 'company': 656,\n",
              " 'moron': 657,\n",
              " 'problems': 658,\n",
              " 'often': 659,\n",
              " 'rule': 660,\n",
              " 'g': 661,\n",
              " 'needed': 662,\n",
              " 'film': 663,\n",
              " 'reply': 664,\n",
              " 'cheers': 665,\n",
              " 'username': 666,\n",
              " '000': 667,\n",
              " 'white': 668,\n",
              " 'become': 669,\n",
              " 'status': 670,\n",
              " '9': 671,\n",
              " 'taking': 672,\n",
              " 'com': 673,\n",
              " 'certain': 674,\n",
              " 'piece': 675,\n",
              " 'present': 676,\n",
              " 'music': 677,\n",
              " 'uploaded': 678,\n",
              " 'stated': 679,\n",
              " 'vandalize': 680,\n",
              " 'terms': 681,\n",
              " \"haven't\": 682,\n",
              " 'citation': 683,\n",
              " 'tags': 684,\n",
              " 'sort': 685,\n",
              " 'generally': 686,\n",
              " '14': 687,\n",
              " 'class': 688,\n",
              " 'soon': 689,\n",
              " 'jew': 690,\n",
              " 'short': 691,\n",
              " 'open': 692,\n",
              " 'explanation': 693,\n",
              " 'google': 694,\n",
              " 'unblock': 695,\n",
              " 'follow': 696,\n",
              " 'fine': 697,\n",
              " 'guys': 698,\n",
              " 'definition': 699,\n",
              " 'likely': 700,\n",
              " 'description': 701,\n",
              " 'alone': 702,\n",
              " 'otherwise': 703,\n",
              " 'cite': 704,\n",
              " 'theory': 705,\n",
              " 'band': 706,\n",
              " 'aware': 707,\n",
              " 'cited': 708,\n",
              " 'points': 709,\n",
              " 'indeed': 710,\n",
              " 'recently': 711,\n",
              " 'entire': 712,\n",
              " 'week': 713,\n",
              " 'ban': 714,\n",
              " 'family': 715,\n",
              " 'proposed': 716,\n",
              " 'shows': 717,\n",
              " 'interesting': 718,\n",
              " 'type': 719,\n",
              " 'bitch': 720,\n",
              " 'saw': 721,\n",
              " 'external': 722,\n",
              " 'set': 723,\n",
              " 'actual': 724,\n",
              " 'mr': 725,\n",
              " 'appear': 726,\n",
              " 'bark': 727,\n",
              " '2004': 728,\n",
              " 'area': 729,\n",
              " 'sourced': 730,\n",
              " 'decide': 731,\n",
              " 'faggot': 732,\n",
              " 'story': 733,\n",
              " 'contributing': 734,\n",
              " 'university': 735,\n",
              " 'jewish': 736,\n",
              " '16': 737,\n",
              " 'conflict': 738,\n",
              " 'contact': 739,\n",
              " 'views': 740,\n",
              " 'moved': 741,\n",
              " 'simple': 742,\n",
              " 'internet': 743,\n",
              " 'told': 744,\n",
              " 'email': 745,\n",
              " 'context': 746,\n",
              " 'black': 747,\n",
              " 'various': 748,\n",
              " 'test': 749,\n",
              " 'members': 750,\n",
              " 'copy': 751,\n",
              " 'balls': 752,\n",
              " 'themselves': 753,\n",
              " 'attention': 754,\n",
              " 'improve': 755,\n",
              " \"article's\": 756,\n",
              " 'john': 757,\n",
              " 'allowed': 758,\n",
              " 'thus': 759,\n",
              " 'death': 760,\n",
              " 'obvious': 761,\n",
              " 'human': 762,\n",
              " 'hours': 763,\n",
              " 'disagree': 764,\n",
              " 'ones': 765,\n",
              " 'author': 766,\n",
              " 'third': 767,\n",
              " 'works': 768,\n",
              " 'bias': 769,\n",
              " 'went': 770,\n",
              " 'proper': 771,\n",
              " 'citations': 772,\n",
              " 'addition': 773,\n",
              " 'result': 774,\n",
              " \"aren't\": 775,\n",
              " \"wouldn't\": 776,\n",
              " 'sites': 777,\n",
              " 'previous': 778,\n",
              " 'nonsense': 779,\n",
              " 'together': 780,\n",
              " 'hand': 781,\n",
              " 'actions': 782,\n",
              " 'pro': 783,\n",
              " '18': 784,\n",
              " 'r': 785,\n",
              " '19': 786,\n",
              " 'goes': 787,\n",
              " 'avoid': 788,\n",
              " 'longer': 789,\n",
              " 'science': 790,\n",
              " 'happened': 791,\n",
              " 'dick': 792,\n",
              " 'im': 793,\n",
              " 'himself': 794,\n",
              " '13': 795,\n",
              " 'automatically': 796,\n",
              " 'valid': 797,\n",
              " 'enjoy': 798,\n",
              " 'n': 799,\n",
              " 'job': 800,\n",
              " 'creating': 801,\n",
              " 'exist': 802,\n",
              " 'respect': 803,\n",
              " 'play': 804,\n",
              " 'biased': 805,\n",
              " 'rights': 806,\n",
              " 'german': 807,\n",
              " 'large': 808,\n",
              " 'deal': 809,\n",
              " 'seriously': 810,\n",
              " 'comes': 811,\n",
              " '17': 812,\n",
              " 'worked': 813,\n",
              " 'level': 814,\n",
              " \"what's\": 815,\n",
              " 'accepted': 816,\n",
              " 'proof': 817,\n",
              " 'meaning': 818,\n",
              " 'helpful': 819,\n",
              " 'series': 820,\n",
              " '21': 821,\n",
              " 'hell': 822,\n",
              " 'available': 823,\n",
              " 'f': 824,\n",
              " 'okay': 825,\n",
              " 'living': 826,\n",
              " 'standard': 827,\n",
              " 'kill': 828,\n",
              " 'act': 829,\n",
              " 'debate': 830,\n",
              " 'calling': 831,\n",
              " 'manual': 832,\n",
              " 'months': 833,\n",
              " 'indicate': 834,\n",
              " 'personally': 835,\n",
              " 'tildes': 836,\n",
              " '23': 837,\n",
              " 'accurate': 838,\n",
              " 'violation': 839,\n",
              " '30': 840,\n",
              " 'criticism': 841,\n",
              " \"shouldn't\": 842,\n",
              " 'historical': 843,\n",
              " 'opinions': 844,\n",
              " 'accept': 845,\n",
              " 'jews': 846,\n",
              " 'width': 847,\n",
              " 'usually': 848,\n",
              " 'upon': 849,\n",
              " 'attempt': 850,\n",
              " 'assume': 851,\n",
              " 'sections': 852,\n",
              " 'action': 853,\n",
              " 'south': 854,\n",
              " 'multiple': 855,\n",
              " 'statements': 856,\n",
              " 'yeah': 857,\n",
              " 'details': 858,\n",
              " 'greek': 859,\n",
              " \"let's\": 860,\n",
              " 'wanker': 861,\n",
              " '22': 862,\n",
              " 'july': 863,\n",
              " '2009': 864,\n",
              " 'video': 865,\n",
              " 'necessary': 866,\n",
              " 'afd': 867,\n",
              " 'tagged': 868,\n",
              " 'blocking': 869,\n",
              " 'space': 870,\n",
              " 'de': 871,\n",
              " 'serious': 872,\n",
              " '2010': 873,\n",
              " 'situation': 874,\n",
              " \"they're\": 875,\n",
              " 'data': 876,\n",
              " 'shall': 877,\n",
              " 'rest': 878,\n",
              " 'march': 879,\n",
              " 'speak': 880,\n",
              " 'refer': 881,\n",
              " 'doubt': 882,\n",
              " 'uk': 883,\n",
              " 'cause': 884,\n",
              " 'explaining': 885,\n",
              " \"you'll\": 886,\n",
              " 'quality': 887,\n",
              " 'apparently': 888,\n",
              " 'separate': 889,\n",
              " 'fix': 890,\n",
              " 'period': 891,\n",
              " 'o': 892,\n",
              " 'india': 893,\n",
              " 'complete': 894,\n",
              " 'lack': 895,\n",
              " 'messages': 896,\n",
              " 'heard': 897,\n",
              " 'none': 898,\n",
              " 'record': 899,\n",
              " 'legal': 900,\n",
              " \"'\": 901,\n",
              " 'countries': 902,\n",
              " 'directly': 903,\n",
              " 'asking': 904,\n",
              " 'sock': 905,\n",
              " 'culture': 906,\n",
              " 'run': 907,\n",
              " 'prove': 908,\n",
              " 'early': 909,\n",
              " 'gets': 910,\n",
              " 'august': 911,\n",
              " 'changing': 912,\n",
              " 'online': 913,\n",
              " 'wikipedian': 914,\n",
              " 'close': 915,\n",
              " 'civil': 916,\n",
              " 'head': 917,\n",
              " 'contribute': 918,\n",
              " 'team': 919,\n",
              " 'meant': 920,\n",
              " 'uses': 921,\n",
              " 'church': 922,\n",
              " 'supposed': 923,\n",
              " 'sucks': 924,\n",
              " 'computer': 925,\n",
              " '50': 926,\n",
              " 'born': 927,\n",
              " 'primary': 928,\n",
              " '25': 929,\n",
              " 'except': 930,\n",
              " 'difference': 931,\n",
              " 'described': 932,\n",
              " 'warring': 933,\n",
              " 'box': 934,\n",
              " 'rationale': 935,\n",
              " 'existing': 936,\n",
              " 'behavior': 937,\n",
              " 'reported': 938,\n",
              " 'significant': 939,\n",
              " 'photo': 940,\n",
              " 'couple': 941,\n",
              " 'produce': 942,\n",
              " 'red': 943,\n",
              " 'military': 944,\n",
              " 'incorrect': 945,\n",
              " 'disruptive': 946,\n",
              " 'release': 947,\n",
              " 'modern': 948,\n",
              " 'field': 949,\n",
              " 'outside': 950,\n",
              " 'bot': 951,\n",
              " 'purpose': 952,\n",
              " 'inclusion': 953,\n",
              " 'among': 954,\n",
              " 'abuse': 955,\n",
              " 'anonymous': 956,\n",
              " 'force': 957,\n",
              " 'specifically': 958,\n",
              " 'pillars': 959,\n",
              " 'border': 960,\n",
              " 'cases': 961,\n",
              " 'character': 962,\n",
              " 'table': 963,\n",
              " 'sometimes': 964,\n",
              " 'scientific': 965,\n",
              " 'vote': 966,\n",
              " 'special': 967,\n",
              " 'friend': 968,\n",
              " 'half': 969,\n",
              " 'june': 970,\n",
              " 'possibly': 971,\n",
              " 'member': 972,\n",
              " 'earlier': 973,\n",
              " 'million': 974,\n",
              " 'damn': 975,\n",
              " 'particularly': 976,\n",
              " 'arguments': 977,\n",
              " 'wait': 978,\n",
              " 'error': 979,\n",
              " 'access': 980,\n",
              " 'linked': 981,\n",
              " 'thinking': 982,\n",
              " 'gave': 983,\n",
              " 'putting': 984,\n",
              " 'allow': 985,\n",
              " 'align': 986,\n",
              " 'tv': 987,\n",
              " 'tutorial': 988,\n",
              " 'numbers': 989,\n",
              " 'majority': 990,\n",
              " 'coming': 991,\n",
              " 'business': 992,\n",
              " 'fan': 993,\n",
              " 'north': 994,\n",
              " 'absolutely': 995,\n",
              " 'international': 996,\n",
              " 'finally': 997,\n",
              " 'entirely': 998,\n",
              " 'control': 999,\n",
              " 'totally': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "sA0ISqNf_x7C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jORksbHL_xT8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "traincnndata = pad_sequences(trainingsequences, maxlen=MAXSEQLENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bb4utvBNRe4Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "dea438fb-ca24-44ce-fa92-9cebe75e6de6"
      },
      "cell_type": "code",
      "source": [
        "traincnndata.shape\n",
        "# np.save(r'~/.Data/traincnndata', traincnndata)\n",
        "traincnndata.tofile(r'~/.Data/traincnndata.dat')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-bde0f7216125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraincnndata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# np.save(r'~/.Data/traincnndata', traincnndata)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtraincnndata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'~/.Data/traincnndata.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '~/.Data/traincnndata.dat'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "7zKFhy-a_xNt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3548224-835c-4aa8-ae36-32473f421ce5"
      },
      "cell_type": "code",
      "source": [
        "trainembeddingweights = np.zeros((len(trainwordindex)+1, EMBEDDINGDIM))\n",
        "for word,index in trainwordindex.items():\n",
        "    trainembeddingweights[index,:] = word2vec[word] if word in word2vec else np.random.rand(EMBEDDINGDIM)\n",
        "print(trainembeddingweights.shape)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(190290, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TpBDUfSp7LBk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "testsequences = tokenizer.texts_to_sequences(cleantestcomments[\"comment_text\"].tolist())\n",
        "testcnndata = pad_sequences(testsequences, maxlen=MAXSEQLENGTH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GGmbNXL3ebHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fcffc562-e93e-45bf-c692-d11d6ae103ae"
      },
      "cell_type": "code",
      "source": [
        "testcnndata.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153164, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "adiNvb3OY06j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import MaxPooling1D, Conv1D, Embedding\n",
        "from keras.layers import Input, Flatten, Dropout, Dense, Merge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0iurFqZU7LMl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Defining the cnn\n",
        "def convNet(embeddings, max_sequence_length, num_words, embedding_dim, labels_index, trainable=False, extra_conv=True):\n",
        "  embedding_layer = Embedding(num_words, \n",
        "                              embedding_dim, \n",
        "                              weights=[embeddings], \n",
        "                              input_length= max_sequence_length, \n",
        "                              trainable= trainable)\n",
        "  sequence_input = Input(shape= (max_sequence_length,),dtype='int32')\n",
        "  embedded_sequence = embedding_layer(sequence_input)\n",
        "  \n",
        "  convs = []\n",
        "  filter_sizes = [3,4,5]\n",
        "  \n",
        "  for filter_size in filter_sizes:\n",
        "    conv_1 = Conv1D(filters=128, kernel_size= filter_size, activation='relu')(embedded_sequence)\n",
        "    pool_1 = MaxPooling1D(pool_size = 3)(conv_1)\n",
        "    convs.append(conv_1)\n",
        "    \n",
        "  merge_1 = Merge(mode='concat', concat_axis=1)(convs)\n",
        "  \n",
        "  # add a 1D convnet with global maxpooling,\n",
        "  conv = Conv1D(filters = 128, kernel_size = 3, activation='relu')(embedded_sequence)\n",
        "  pool = MaxPooling1D(pool_size =3)(conv)\n",
        "  \n",
        "  if extra_conv:\n",
        "    x = Dropout(0.5)(merge_1)\n",
        "  else:\n",
        "    x = Dropout(0.5)(pool)\n",
        "  x= Flatten()(x)\n",
        "  x = Dense(128, activation='relu')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  # Finally, we feed the output into a Sigmoid layer.\n",
        "    # The reason why sigmoid is used is because we are trying to achieve a binary classification(1,0) \n",
        "    # for each of the 6 labels, and the sigmoid function will squash the output between the bounds of 0 and 1.\n",
        "  preds = Dense(labels_index, activation='sigmoid')(x)\n",
        "  model = Model(sequence_input, preds)\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "               optimizer='adam',\n",
        "               metrics=['acc'])\n",
        "  model.summary()\n",
        "  return model\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPE8hRRq7K3r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = traincnndata\n",
        "y_tr = ytrain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g4Sy5dP-7K13",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "4086a37a-6fca-43aa-be5c-f77d2753b976"
      },
      "cell_type": "code",
      "source": [
        "model =convNet(trainembeddingweights, MAXSEQLENGTH, len(trainwordindex)+1, EMBEDDINGDIM, \n",
        "                len(list(label_names)), False)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 200)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 200, 300)     57087000    input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 198, 128)     115328      embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 197, 128)     153728      embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 196, 128)     192128      embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "merge_4 (Merge)                 (None, 591, 128)     0           conv1d_13[0][0]                  \n",
            "                                                                 conv1d_14[0][0]                  \n",
            "                                                                 conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 591, 128)     0           merge_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 75648)        0           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 128)          9683072     flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 6)            774         dropout_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 67,232,030\n",
            "Trainable params: 10,145,030\n",
            "Non-trainable params: 57,087,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "L_5D1PWn3fn9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfudqZ4Zg1i0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#DEFINING CALLBACKS\n",
        "earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n",
        "callbackslist = [earlystopping]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ghpolgKrg1s9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "760b4e52-6e66-42c7-f0af-bb1369e71d60"
      },
      "cell_type": "code",
      "source": [
        "#TRAINING THE NETWORK\n",
        "hist = model.fit(x_train, y_tr, epochs=epochs, callbacks=callbackslist, validation_split=0.1, shuffle=True, batch_size=batchsize)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/3\n",
            "143613/143613 [==============================] - 64s 443us/step - loss: 0.1025 - acc: 0.9667 - val_loss: 0.0770 - val_acc: 0.9734\n",
            "Epoch 2/3\n",
            "143613/143613 [==============================] - 61s 424us/step - loss: 0.0720 - acc: 0.9748 - val_loss: 0.0641 - val_acc: 0.9769\n",
            "Epoch 3/3\n",
            "143613/143613 [==============================] - 61s 423us/step - loss: 0.0628 - acc: 0.9774 - val_loss: 0.0607 - val_acc: 0.9786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jPVOFBnog1z-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "09cc97a3-cba0-4432-8ee6-d4fd587c7ac5"
      },
      "cell_type": "code",
      "source": [
        "ytest = model.predict(testcnndata, batch_size=1024, verbose=1)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 20s 133us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h_17pAz9g18Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "18f406e3-4c53-4e0f-a1bf-a5c941aed5ab"
      },
      "cell_type": "code",
      "source": [
        "ytest"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.8224966e-03, 1.1830821e-08, 4.2200327e-04, 7.7522920e-08,\n",
              "        3.9522862e-04, 2.3171215e-06],\n",
              "       [2.0661957e-04, 4.9932680e-09, 3.0144551e-05, 3.2527669e-08,\n",
              "        1.9507163e-05, 3.5366691e-07],\n",
              "       [1.9115401e-02, 3.5912668e-05, 4.0444843e-03, 1.0097566e-04,\n",
              "        4.1149175e-03, 3.9079532e-04],\n",
              "       ...,\n",
              "       [7.4161440e-02, 2.7444616e-05, 1.9498613e-02, 4.5952565e-05,\n",
              "        2.1717064e-02, 8.7683101e-04],\n",
              "       [3.0129500e-02, 4.4708208e-06, 6.2397514e-03, 1.1525640e-05,\n",
              "        4.6928748e-03, 1.2251244e-04],\n",
              "       [2.5731808e-01, 6.1618083e-04, 7.7538729e-02, 9.6944702e-04,\n",
              "        8.4814802e-02, 6.1101485e-03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "ZfHnoWXJg155",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "10e6569e-a1de-4902-b0ea-107515079291"
      },
      "cell_type": "code",
      "source": [
        "!ls ~/.Data"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GoogleNews-vectors-negative300.bin.gz\t      test.csv.zip\n",
            "googles-trained-word2vec-model-in-python.zip  test_labels.csv.zip\n",
            "sample_submission.csv.zip\t\t      traincleandata.csv\n",
            "testcleandata.csv\t\t\t      trainCleanDatatokens.csv\n",
            "testCleanDatatokens.csv\t\t\t      train.csv\n",
            "test.csv\t\t\t\t      train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "75Admep0g13m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NYSII18Xg1qf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WmBeWJIhg1oo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tjO-nFwhg1m8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}