{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective : To try hand at feature engineering \n",
    "- learn the importance \n",
    "- some techniques\n",
    "\n",
    "\n",
    "Dataset : https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(r'./Data/feature_engineering/train.csv',index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 159571 entries, 0000997932d777bf to fff46fc426af1f9a\n",
      "Data columns (total 7 columns):\n",
      "comment_text     159571 non-null object\n",
      "toxic            159571 non-null int64\n",
      "severe_toxic     159571 non-null int64\n",
      "obscene          159571 non-null int64\n",
      "threat           159571 non-null int64\n",
      "insult           159571 non-null int64\n",
      "identity_hate    159571 non-null int64\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 9.7+ MB\n",
      "None\n",
      "               toxic   severe_toxic        obscene         threat  \\\n",
      "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
      "mean        0.095844       0.009996       0.052948       0.002996   \n",
      "std         0.294379       0.099477       0.223931       0.054650   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "              insult  identity_hate  \n",
      "count  159571.000000  159571.000000  \n",
      "mean        0.049364       0.008805  \n",
      "std         0.216627       0.093420  \n",
      "min         0.000000       0.000000  \n",
      "25%         0.000000       0.000000  \n",
      "50%         0.000000       0.000000  \n",
      "75%         0.000000       0.000000  \n",
      "max         1.000000       1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.info())\n",
    "print(df_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment_text     0\n",
      "toxic            0\n",
      "severe_toxic     0\n",
      "obscene          0\n",
      "threat           0\n",
      "insult           0\n",
      "identity_hate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# checking the null values\n",
    "print(df_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ffe987279560d7ff</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffea4adeee384e90</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffee36eab5c267c9</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff125370e4aaaf3</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff46fc426af1f9a</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "ffe987279560d7ff  \":::::And for the second time of asking, when ...      0   \n",
       "ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "fff125370e4aaaf3  And it looks like it was actually you who put ...      0   \n",
       "fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                                      \n",
       "ffe987279560d7ff             0        0       0       0              0  \n",
       "ffea4adeee384e90             0        0       0       0              0  \n",
       "ffee36eab5c267c9             0        0       0       0              0  \n",
       "fff125370e4aaaf3             0        0       0       0              0  \n",
       "fff46fc426af1f9a             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "ffe987279560d7ff    \":::::And for the second time of asking, when ...\n",
       "ffea4adeee384e90    You should be ashamed of yourself \\n\\nThat is ...\n",
       "ffee36eab5c267c9    Spitzer \\n\\nUmm, theres no actual article for ...\n",
       "fff125370e4aaaf3    And it looks like it was actually you who put ...\n",
       "fff46fc426af1f9a    \"\\nAnd ... I really don't think you understand...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['comment_text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            15294\n",
       "severe_toxic      1595\n",
       "obscene           8449\n",
       "threat             478\n",
       "insult            7877\n",
       "identity_hate     1405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[:,['toxic','severe_toxic','obscene','threat','insult','identity_hate']].apply(sum, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANING UP THE TEXT\n",
    "#Function to clean up the text\n",
    "def standardizetext(df, textfield):\n",
    "    df[textfield] = df[textfield].str.replace(r\"http\\S+\", \"\")\n",
    "    df[textfield] = df[textfield].str.replace(r\"http\", \"\")\n",
    "    df[textfield] = df[textfield].str.replace(r\"@\\S+\", \"\")\n",
    "    df[textfield] = df[textfield].str.replace(r\"[^A-Za-z0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[textfield] = df[textfield].str.replace(r\"@\", \"at\")\n",
    "    df[textfield] = df[textfield].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>hey man, i'm really not trying to edit war  it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>you, sir, are my hero  any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "0000997932d777bf  explanation\\nwhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  d'aww! he matches this background colour i'm s...      0   \n",
       "000113f07ec002fd  hey man, i'm really not trying to edit war  it...      0   \n",
       "0001b41b1c6bb37e  \"\\nmore\\ni can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  you, sir, are my hero  any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                                      \n",
       "0000997932d777bf             0        0       0       0              0  \n",
       "000103f0d9cfb60f             0        0       0       0              0  \n",
       "000113f07ec002fd             0        0       0       0              0  \n",
       "0001b41b1c6bb37e             0        0       0       0              0  \n",
       "0001d958c54c6e35             0        0       0       0              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = standardizetext(df_train, \"comment_text\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train['comment_text']\n",
    "Y = df_train.drop(['comment_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,train_size=0.8, test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(decode_error='ignore',  min_df=0.009,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf_vectorizer.fit_transform(X_train)\n",
    "X_test = tf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OneVsRestClassifier(LinearSVC())\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9073476421745261"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score on test dataset\n",
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9078930876731215"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy score on train dataset\n",
    "model.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88d640ab9223398d</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9f9b412e0a99e6dc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323848f9f866c47e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90bd2ed36352d163</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe77e59403ac395e</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17e22e51f52ae4a4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1d80e1ab696b108</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329101468aa1b93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4c4cae190527b2a1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e9c6a8772267b3c</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "id                                                                           \n",
       "88d640ab9223398d      0             0        0       0       0              0\n",
       "9f9b412e0a99e6dc      0             0        0       0       0              0\n",
       "323848f9f866c47e      0             0        0       0       0              0\n",
       "90bd2ed36352d163      0             0        0       0       0              0\n",
       "fe77e59403ac395e      0             0        0       0       0              0\n",
       "17e22e51f52ae4a4      0             0        0       0       0              0\n",
       "b1d80e1ab696b108      0             0        0       0       0              0\n",
       "9329101468aa1b93      0             0        0       0       0              0\n",
       "4c4cae190527b2a1      0             0        0       0       0              0\n",
       "8e9c6a8772267b3c      1             0        0       0       0              0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_one_v_one = OneVsOneClassifier(LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_one_v_one.fit(X_train,Y_train)\n",
    "# model_one_v_one.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using Multiple Output regressor -\n",
    "\n",
    "Multiple out regressor fits multiple regressor - this stratergy fits one regressor per target. Since each traget is represented by exactly one regressor  it is possible to drive strength out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = MultiOutputClassifier(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "           n_jobs=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "multi_model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.905342315525615"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9102196528169455"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_model.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  UnderStanding TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df_train = df_train['comment_text']\n",
    "\n",
    "x_df_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_vectorizer = TfidfVectorizer(decode_error='ignore',  min_df=0.009,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = tf_vectorizer.fit_transform(x_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 454)\n",
      "['10', '100', '11', '12', '14', '15', '20', '2005', '2006', '2007', '2008', '24', 'able', 'according', 'account', 'actual', 'actually', 'add', 'added', 'adding', 'address', 'admin', 'administrator', 'admins', 'ago', 'agree', 'allowed', 'american', 'answer', 'anti', 'appear', 'appears', 'appreciate', 'appropriate', 'aren', 'argument', 'article', 'articles', 'ask', 'asked', 'attack', 'attacks', 'attention', 'automatically', 'aware', 'away', 'bad', 'based', 'believe', 'best', 'better', 'big', 'bit', 'block', 'blocked', 'book', 'books', 'called', 'came', 'care', 'case', 'category', 'certain', 'certainly', 'change', 'changed', 'changes', 'check', 'cheers', 'cited', 'claim', 'claims', 'clear', 'clearly', 'come', 'comment', 'comments', 'common', 'community', 'completely', 'consensus', 'consider', 'considered', 'contact', 'content', 'continue', 'contribs', 'contributing', 'contributions', 'copyright', 'correct', 'country', 'course', 'create', 'created', 'criteria', 'current', 'currently', 'date', 'day', 'days', 'decide', 'delete', 'deleted', 'deleting', 'deletion', 'description', 'did', 'didn', 'different', 'disagree', 'discuss', 'discussion', 'dispute', 'does', 'doesn', 'doing', 'don', 'dont', 'edit', 'edited', 'editing', 'editor', 'editors', 'edits', 'encyclopedia', 'end', 'english', 'enjoy', 'entire', 'entry', 'especially', 'evidence', 'exactly', 'example', 'explain', 'fact', 'facts', 'fair', 'faith', 'false', 'far', 'feel', 'fine', 'follow', 'following', 'form', 'free', 'fuck', 'fucking', 'future', 'general', 'generally', 'getting', 'given', 'going', 'good', 'got', 'great', 'group', 'guess', 'guidelines', 'guy', 'happy', 'hard', 'haven', 'having', 'hello', 'help', 'hey', 'hi', 'high', 'history', 'hope', 'idea', 'image', 'images', 'important', 'include', 'included', 'including', 'info', 'information', 'instead', 'interested', 'interesting', 'involved', 'ip', 'isn', 'issue', 'issues', 'just', 'kind', 'know', 'knowledge', 'known', 'language', 'later', 'lead', 'learn', 'leave', 'left', 'let', 'life', 'like', 'likely', 'line', 'link', 'links', 'list', 'listed', 'little', 'live', 'll', 'long', 'look', 'looking', 'looks', 'lot', 'love', 'main', 'major', 'make', 'makes', 'making', 'man', 'material', 'matter', 'maybe', 'mean', 'means', 'media', 'mention', 'mentioned', 'message', 'mind', 'moved', 'names', 'need', 'needed', 'needs', 'neutral', 'new', 'news', 'nice', 'non', 'notability', 'notable', 'note', 'notice', 'noticed', 'npov', 'number', 'obvious', 'obviously', 'official', 'oh', 'ok', 'old', 'open', 'opinion', 'order', 'original', 'page', 'pages', 'paragraph', 'particular', 'party', 'past', 'people', 'person', 'personal', 'picture', 'place', 'placed', 'point', 'points', 'policies', 'policy', 'political', 'position', 'possible', 'post', 'posted', 'pov', 'power', 'present', 'pretty', 'probably', 'problem', 'problems', 'process', 'project', 'provide', 'provided', 'public', 'published', 'question', 'questions', 'quite', 'quote', 'read', 'reading', 'real', 'really', 'reason', 'reasons', 'recent', 'recently', 'redirect', 'reference', 'references', 'regarding', 'regards', 'related', 'relevant', 'reliable', 'remember', 'remove', 'removed', 'removing', 'reply', 'report', 'request', 'research', 'response', 'revert', 'reverted', 'reverting', 'review', 'right', 'rule', 'rules', 'said', 'sandbox', 'saw', 'say', 'saying', 'says', 'school', 'search', 'second', 'section', 'seen', 'self', 'sense', 'sentence', 'set', 'shit', 'short', 'shows', 'sign', 'similar', 'simple', 'simply', 'single', 'site', 'small', 'soon', 'sorry', 'sort', 'source', 'sources', 'specific', 'speedy', 'start', 'started', 'state', 'stated', 'statement', 'states', 'status', 'stay', 'stop', 'stuff', 'stupid', 'style', 'subject', 'suggest', 'summary', 'support', 'sure', 'tag', 'taken', 'taking', 'talk', 'talking', 'tell', 'template', 'term', 'terms', 'text', 'thank', 'thanks', 'thing', 'things', 'think', 'thought', 'time', 'times', 'title', 'today', 'took', 'topic', 'tried', 'true', 'truth', 'try', 'trying', 'type', 'understand', 'unless', 'use', 'used', 'useful', 'user', 'users', 'using', 'utc', 'vandalism', 'vandalize', 'various', 've', 'version', 'view', 'want', 'wanted', 'war', 'warning', 'wasn', 'way', 'web', 'website', 'week', 'welcome', 'wiki', 'wikipedia', 'wish', 'won', 'word', 'words', 'work', 'working', 'world', 'wouldn', 'wp', 'write', 'writing', 'written', 'wrong', 'wrote', 'year', 'years', 'yes']\n",
      "454\n"
     ]
    }
   ],
   "source": [
    "print(trans.shape)\n",
    "print(tf_vectorizer.get_feature_names())\n",
    "print(len(tf_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyzer': 'word', 'binary': False, 'decode_error': 'ignore', 'dtype': <class 'numpy.int64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': None, 'min_df': 0.009, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': 'english', 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}\n"
     ]
    }
   ],
   "source": [
    "print(tf_vectorizer.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'get', 'part', 'that', 'three', 'yourself', 'seemed', 'bottom', 'cant', 'may', 'my', 'formerly', 'hasnt', 'throughout', 'wherever', 'amongst', 'another', 'couldnt', 'might', 'such', 'been', 'he', 'otherwise', 'will', 'anywhere', 'yet', 'via', 'cannot', 'mill', 'besides', 'towards', 'amount', 'back', 'nine', 'side', 'empty', 'everything', 'either', 'sixty', 'ten', 'whenever', 'you', 'eg', 'none', 'something', 'therein', 'front', 'ever', 'for', 'these', 'else', 'too', 'where', 'who', 'much', 'moreover', 'noone', 'former', 'full', 'over', 'until', 'thereupon', 'beforehand', 'yours', 'or', 'own', 'name', 'the', 'hereby', 'latterly', 'co', 'more', 'should', 'whoever', 'in', 'enough', 'which', 'very', 'five', 'beyond', 'thence', 'meanwhile', 'move', 'except', 'are', 'being', 'no', 'after', 'again', 'themselves', 'all', 'per', 'often', 'then', 'even', 'anyway', 'someone', 'two', 'by', 'somewhere', 'ourselves', 'hundred', 'anything', 'from', 'am', 'both', 'how', 'namely', 'onto', 'mine', 'now', 'it', 'below', 'please', 'every', 'system', 'thick', 'them', 'those', 'whom', 'himself', 'than', 'anyhow', 'seem', 'down', 'cry', 'only', 'fifteen', 'herself', 'sometimes', 'whole', 'ours', 'together', 'less', 're', 'becomes', 'inc', 'call', 'never', 'however', 'and', 'on', 'upon', 'along', 'found', 'indeed', 'go', 'somehow', 'fill', 'sometime', 'first', 'nowhere', 'must', 'of', 'thereby', 'whereby', 'against', 'others', 'thin', 'made', 'twenty', 'yourselves', 'but', 'thru', 'anyone', 'elsewhere', 'up', 'can', 'our', 'there', 'could', 'toward', 'hereupon', 'several', 'herein', 'next', 'nobody', 'still', 'most', 'find', 'him', 'top', 'everywhere', 'other', 'hereafter', 'they', 'wherein', 'well', 'what', 'had', 'hence', 'before', 'into', 'would', 'forty', 'hers', 'his', 'among', 'last', 'some', 'myself', 'serious', 'eleven', 'ie', 'therefore', 'under', 'within', 'fifty', 'about', 'keep', 'an', 'became', 'was', 'between', 'nevertheless', 'sincere', 'with', 'whence', 'give', 'through', 'without', 'i', 'is', 'many', 'amoungst', 'afterwards', 'already', 'describe', 'least', 'she', 'around', 'have', 'during', 'has', 'itself', 'behind', 'be', 'once', 'this', 'mostly', 'as', 'due', 'we', 'nor', 'become', 'each', 'a', 'here', 'also', 'us', 'were', 'alone', 'because', 'put', 'if', 'everyone', 'latter', 'seeming', 'while', 'your', 'out', 'almost', 'seems', 'few', 'her', 'thereafter', 'me', 'becoming', 'beside', 'always', 'perhaps', 'third', 'six', 'detail', 'four', 'whereafter', 'off', 'whither', 'when', 'whether', 'to', 'un', 'whereas', 'its', 'any', 'same', 'across', 'since', 'con', 'at', 'so', 'bill', 'though', 'neither', 'do', 'not', 'done', 'one', 'de', 'whatever', 'above', 'etc', 'although', 'whose', 'why', 'see', 'eight', 'further', 'nothing', 'ltd', 'rather', 'their', 'fire', 'twelve', 'thus', 'whereupon', 'take', 'show', 'interest'})\n"
     ]
    }
   ],
   "source": [
    "print(tf_vectorizer.get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary -- Take Aways\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References :\n",
    "https://www.kaggle.com/eikedehling/feature-engineering\n",
    "\n",
    "[Multi Class Classification](# https://www.youtube.com/watch?v=y0wQK3mnrNY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
